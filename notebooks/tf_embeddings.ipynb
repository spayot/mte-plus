{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d2c1e6-b362-49ab-bca0-454739b9622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "sys.path.append('../src')\n",
    "import columnar as col\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0a107-c4e1-4051-a4f0-55d13997f032",
   "metadata": {},
   "source": [
    "# Categorical Embeddings\n",
    "Alternative to General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8da331f-1de6-467b-bbee-99a624ab18b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c25718-6d87-4b0f-a0a4-3f6806c26332",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = col.loaders.petfinder._load('../')\n",
    "feature_selection = col.FeatureSelection(**col.loaders.petfinder._select_features(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5252c2bc-032f-4b27-adad-9eeded512866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7200693657039952"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dad7d1a-2d6e-40d1-959b-f63ba31166bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 2,\n",
       " 'age': 106,\n",
       " 'breed1': 176,\n",
       " 'breed2': 135,\n",
       " 'gender': 3,\n",
       " 'color1': 7,\n",
       " 'color2': 7,\n",
       " 'color3': 6,\n",
       " 'maturitysize': 4,\n",
       " 'furlength': 3,\n",
       " 'vaccinated': 3,\n",
       " 'dewormed': 3,\n",
       " 'sterilized': 3,\n",
       " 'health': 3,\n",
       " 'quantity': 19,\n",
       " 'fee': 74,\n",
       " 'state': 14,\n",
       " 'rescuerid': 5595,\n",
       " 'videoamt': 9,\n",
       " 'photoamt': 31,\n",
       " 'has_name': 2,\n",
       " 'target': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{col: df[col].nunique() for col in df.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f27cb803-d8cd-4eb6-94c3-4b98552bc8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 14:20:05.703952: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-26 14:20:05.704087: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "ds = col.embeddings.df_to_dataset(df, 'target', batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40e0bad3-a6a6-4ae2-8aad-5158b8cfe552",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df_to_dataset(df, 'target', batch_size=5)\n",
    "[(train_features, label_batch)] = ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e91d7e73-5bea-42f8-99d6-a05d3bc83850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "columnar.embeddings.tf_preprocessing.TFEmbeddingLayer"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.TFEmbeddingLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5317a61b-9c2d-4933-bb28-570c8c91ca29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['type', 'age', 'breed1', 'breed2', 'gender', 'color1', 'color2', 'color3', 'maturitysize', 'furlength', 'vaccinated', 'dewormed', 'sterilized', 'health', 'quantity', 'fee', 'state', 'rescuerid', 'videoamt', 'photoamt', 'has_name'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac1eec5-2fd3-42ae-af45-8528cedb3d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feats = col.FeatureSelection(target='target',categoricals=['type'], numericals=['photoamt', 'videoamt', 'fee', 'age'])\n",
    "transformer = col.MeanTargetEncoder(feats)\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "pipe = col.CategoricalPipeline(features=feats,\n",
    "                               transform=transformer,\n",
    "                               scaler=None,\n",
    "                               model=model,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e2bc595-a721-4110-8488-8ee9c0f255a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "178f9e9b-3593-471e-8566-5618822cc392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51777799-79ce-4f86-a244-4a13b267a37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_</th>\n",
       "      <th>photoamt</th>\n",
       "      <th>videoamt</th>\n",
       "      <th>fee</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PetID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86e1089a3</th>\n",
       "      <td>0.740111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296e909a</th>\n",
       "      <td>0.740111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422e4906</th>\n",
       "      <td>0.703158</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842f1ff5</th>\n",
       "      <td>0.703158</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850a43f90</th>\n",
       "      <td>0.703158</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              type_  photoamt  videoamt  fee  age\n",
       "PetID                                            \n",
       "86e1089a3  0.740111       1.0         0  100    3\n",
       "6296e909a  0.740111       2.0         0    0    1\n",
       "3422e4906  0.703158       7.0         0    0    1\n",
       "5842f1ff5  0.703158       8.0         0  150    4\n",
       "850a43f90  0.703158       3.0         0    0    1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.pipe.steps[0][1].transform(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87c83429-3436-4b63-a1ca-5fff3ecf848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72730883 0.83452213 0.86059307 0.66455585 0.81519586]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8396311555817147"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "pipe = col.CategoricalPipeline(features=feature_selection,\n",
    "                              transform=col.MeanTargetEncoder(feats),\n",
    "                              model=RandomForestClassifier(max_depth=5, n_estimators=100))\n",
    "\n",
    "pipe.fit(df)\n",
    "print(pipe.predict(df.head()))\n",
    "f1_score(df.target, (pipe.predict(df) > .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ae16c2-3fcb-4f07-b5b6-68725250f604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 5990)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.base import TransformerMixin\n",
    "\n",
    "# class TotalTransformer(TransformerMixin):\n",
    "#     def __init__(self, features, cat_encoder):\n",
    "#         self.features = features\n",
    "#         self.cat_encoder = cat_encoder\n",
    "#         self.transformer = ColumnTransformer(\n",
    "#             [('categories', cat_encoder, features.categoricals)], \n",
    "#             remainder='passthrough')\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self.transformer.fit(X,y)\n",
    "        \n",
    "#     def transform(self, X):\n",
    "#         return self.transformer.transform(X)\n",
    "    \n",
    "#     def get_params(self, deep: bool = True):\n",
    "#         cat_encoder = clone(self.cat_encoder) if deep else self.cat_encoder\n",
    "#         return {'features': self.features, 'cat_encoder': cat_encoder}\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "tt = col.TransformStrategy(feature_selection, OneHotEncoder())\n",
    "tt.fit_transform(df).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d157596-ab0f-4af1-9c32-893383e5523f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74712157 0.70827339 0.74445654 0.70714241 0.75170743]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8372561945015317"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = col.CategoricalPipeline(features=feature_selection,\n",
    "                              transform=col.TransformStrategy(feature_selection, OneHotEncoder()),\n",
    "                              model=RandomForestClassifier(max_depth=5, n_estimators=100))\n",
    "\n",
    "pipe.fit(df)\n",
    "print(pipe.predict(df.head()))\n",
    "f1_score(df.target, (pipe.predict(df) > .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76f80ec1-d62a-4571-a901-45c43377a30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals = pd.DataFrame(data={'e': {'a': 1 , 'b': 2}, 'f': {'a': 3 , 'b': 4}})\n",
    "errs = vals * .3\n",
    "\n",
    "vals.plot.bar(yerr=errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a708e305-5258-4e4b-ae00-568ba03e5267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data = np.array([[0,2,.3], [1,4,.4], [2,3,.15]])\n",
    "plt.figure()\n",
    "yerr_ = np.tile(data[:,2]/2, (2,1))\n",
    "plt.bar(data[:,0], data[:,1], yerr=yerr_)\n",
    "plt.xlim([-1,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e021d4e3-3c93-473d-87fc-fcd489a8501b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categories': 'auto',\n",
       " 'drop': None,\n",
       " 'dtype': numpy.float64,\n",
       " 'handle_unknown': 'error',\n",
       " 'sparse': True}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test behavior of \n",
    "col.FeatureSelection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "232289a5-142c-46ef-ae40-865ac6c80986",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(train_features, label_batch)] = ds.take(1)\n",
    "\n",
    "feature_selection = col.FeatureSelection(categoricals=['type', 'age', 'breed1', 'breed2', 'gender', 'color1', 'color2', 'color3', 'maturitysize', 'furlength', 'vaccinated', 'dewormed', 'sterilized', 'health', 'quantity', 'state', 'rescuerid', 'has_name'], \n",
    "                                         numericals=['photoamt', 'videoamt', 'fee'], \n",
    "                                         target='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde4319a-fc3d-4457-88df-2d8fdd00f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2, labels = df.drop(columns=['target']), df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0cdd6cd7-f669-4f4f-975b-66d6a4a3fa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff33776d-d388-425c-b54d-eff1101a75a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6185"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.nunique()-1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f663bda-112f-4d90-ae73-5cb4021c0bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': (2, 2),\n",
       " 'age': (106, 106),\n",
       " 'breed1': (176, 176),\n",
       " 'breed2': (135, 135),\n",
       " 'gender': (3, 3),\n",
       " 'color1': (7, 7),\n",
       " 'color2': (7, 7),\n",
       " 'color3': (6, 6),\n",
       " 'maturitysize': (4, 4),\n",
       " 'furlength': (3, 3),\n",
       " 'vaccinated': (3, 3),\n",
       " 'dewormed': (3, 3),\n",
       " 'sterilized': (3, 3),\n",
       " 'health': (3, 3),\n",
       " 'quantity': (19, 19),\n",
       " 'fee': (117, 74),\n",
       " 'state': (14, 14),\n",
       " 'rescuerid': (5595, 5595),\n",
       " 'videoamt': (9, 9),\n",
       " 'photoamt': (31, 31),\n",
       " 'has_name': (2, 2),\n",
       " 'target': (2, 2)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{col: (len([f for f in ohe.get_feature_names_out() if col in f]), df[col].nunique()) for col in df.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ed2dbe9-f707-437d-9293-d53fa9e5ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 11:45:54.278623: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-26 11:45:54.701577: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-26 11:45:54.715150: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-26 11:45:55.589870: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-26 11:45:55.600900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-26 11:45:56.529510: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-26 11:45:56.539644: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 11:45:57.663721: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 5s 12ms/step - loss: 0.6064 - accuracy: 0.5979\n",
      "Epoch 2/3\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5831 - accuracy: 0.6668\n",
      "Epoch 3/3\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5803 - accuracy: 0.6703\n",
      "10/94 [==>...........................] - ETA: 0s - loss: 0.6137 - accuracy: 0.6687 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 11:46:11.209123: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 5ms/step - loss: 0.5722 - accuracy: 0.6986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5721990466117859, 0.698566198348999]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=.2)\n",
    "\n",
    "ds_train = df_to_dataset(df_train, 'target', batch_size=32)\n",
    "ds_test = df_to_dataset(df_test, 'target', batch_size=32)\n",
    "\n",
    "model = col.TFCatEmbsModel(ds_train, feature_selection)\n",
    "# model(train_features)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(ds_train, epochs=3)\n",
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce3fa03d-3e20-467e-b5d1-d345722f54b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 247])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode_features(train_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5776fa-0882-4432-b256-a699c74bfb01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
